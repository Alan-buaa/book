# 快速开始

### 安装MLflow

python ： pip install mlflow

At this point we recommend you follow the [tutorial](https://mlflow.org/docs/latest/tutorials-and-examples/tutorial.html) for a walk-through on how you can leverage MLflow in your daily workflow.

### 下载

Download the quickstart code by cloning MLflow via `git clone https://github.com/mlflow/mlflow`, and cd into the `examples` subdirectory of the repository. We’ll use this working directory for running the `quickstart`.

We avoid running directly from our clone of MLflow as doing so would cause the tutorial to use MLflow from source, rather than your PyPi installation of MLflow.

### 使用Tracking API

[MLflow Tracking API](https://mlflow.org/docs/latest/tracking.html) 可以记录数据科学代码的metrics和artifacts文件，并且可以查看运行历史。参考示例（quickstart/mlflow_tracking.py）

```python
import os
from random import random, randint
from mlflow import log_metric, log_param, log_artifacts

if __name__ == "__main__":
    # Log a parameter (key-value pair)
    log_param("param1", randint(0, 100))

    # Log a metric; metrics can be updated throughout the run
    log_metric("foo", random())
    log_metric("foo", random() + 1)
    log_metric("foo", random() + 2)

    # Log an artifact (output file)
    if not os.path.exists("outputs"):
        os.makedirs("outputs")
    with open("outputs/test.txt", "w") as f:
        f.write("hello world!")
    log_artifacts("outputs")

```

tracking运行后的目录结构

![image-20200831094404756](D:\01.new\07.doc\book\book\mlflow\tracking.png)

### 查看Tracking ui

默认情况下，无论在哪里运行程序，tracking api都会把数据写到./mlruns目录下。可以运行tracking ui查看。

 mlflow ui -h 0.0.0.0 。 然后通过http://localhost:5000查看相关内容。默认绑定的是localhost 以及5000端口，可以通过-h设置绑定的地址，-p设置绑定端口。

![image-20200831094550328](D:\01.new\07.doc\book\book\mlflow\ui.png)

![image-20200831094928742](D:\01.new\07.doc\book\book\mlflow\detail.png)



![image-20200831094713954](D:\01.new\07.doc\book\book\mlflow\compare.png)

![image-20200831094804436](D:\01.new\07.doc\book\book\mlflow\compare_metric.png)

### 运行MLflow工程

MLflow可以将代码及其依赖打包为一个工程，可以使用该工程重新运行其他数据。每个工程包含代码及`MLproject` 文件，该文件定义了代码的依赖（例如python环境）、以及哪些命令可以运行到项目中、工程使用了什么参数。

可以使用`mlflow run`命令方便的运行已存在的工程，可以运行本地的目录或者github uri：

```shell
mlflow run sklearn_elasticnet_wine -P alpha=0.5

mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=5.0
```

![image-20200904151213334](D:\01.new\07.doc\book\book\mlflow\run_project.png)

/notebook/.home/.cache/pip 没有权限

![image-20200904151402548](D:\01.new\07.doc\book\book\mlflow\run1.png)

该工程新创建的conda环境无mlflow模块（该工程的依赖文件里有mlflow，可能由于第一步报错导致mlflow没有安装成功）。*为什么再次运行依然用的是上次创建的conda环境，需要深入研究一下。*

![image-20200904152406720](D:\01.new\07.doc\book\book\mlflow\run_successed.png)

运行后结果都会存放在当前目录下的mlruns目录里

![image-20200904152913014](D:\01.new\07.doc\book\book\mlflow\run_dir.png)

![image-20200904153126033](D:\01.new\07.doc\book\book\mlflow\run_result.png)

![image-20200904153527372](D:\01.new\07.doc\book\book\mlflow\project_ui.png)

![image-20200904154347422](D:\01.new\07.doc\book\book\mlflow\run_detail.png)

![image-20200904154543482](D:\01.new\07.doc\book\book\mlflow\artifacts1.png)

![image-20200904154626450](D:\01.new\07.doc\book\book\mlflow\artifacts2.png)

![image-20200904154729463](D:\01.new\07.doc\book\book\mlflow\artifacts3.png)



![image-20200904154948791](D:\01.new\07.doc\book\book\mlflow\register.png)



`tutorial`目录下有示例工程，工程包括一个说明依赖的`MLflow`文件。如果没有配置 [tracking server](https://mlflow.org/docs/latest/tracking.html#tracking-server)，工程会将 Tracking API数据记录在本地的`mlruns`目录下，可以运行`mlflow ui`查看。

> 默认情况下`mlflow run`使用[conda](https://conda.io/)安装所有依赖。可以使用`--no-conda`选项来禁用conda。再不使用conda的情况下，必须确保所有必须的依赖都已经安装好。

更多信息请查看 [MLflow Projects](https://mlflow.org/docs/latest/projects.html).

### 保存模型并提供模型服务

MLflow包含一个通用的`MLmodel`格式，可以用来在各种工具上以多种形式保存模型。例如，很多模型可以用作python函数，因此为了让各种工具能为模型提供服务一个`MLmodel`文件可以声明每个模型应该如何解释为python函数。MLflow也包含在本地运行这些模型、使用docker容器或者商业服务平台的工具。

为了阐述该功能，`mlflow.sklearn`包将scikit-learn模型记录为MLflow artifacts，然后再次加载模型对外提供服务。

> https://zh.wikipedia.org/wiki/Artifact_(%E8%AE%A1%E7%AE%97%E6%9C%BA)
>
> 通常，Artifact 供其他项目或用户的使用和消费，或者用于部署至寄主系统。在这些例子中，Artifact 通常是一个单一文件。项目之间存在依赖时，又希望避免生产用于发布的Artifact，通常此时，Artifact 将以目录的形式存在。
>
> https://en.wikipedia.org/wiki/Artifact_(software_development)

`sklearn_logistic_regression/train.py`是一个训练应用的例子，可以使用下面的命令运行：

```
python sklearn_logistic_regression/train.py
```

当运行该示例时，针对该实验其输出一个MLflow运行id。当通过mlflow ui查看的时候，可以看到该次运行产生了一个`model`文件夹，该文件夹包含一个`MLmodel`描述文件、一个pickled scikit-learn模型。可以将run ID和artifacts目录里的模型路径（这里是“model”）传递给各种工具，MLflow包含一个基于python模型的简单REST服务：

```
mlflow models serve -m runs:/<RUN_ID>/model
```

> 默认服务使用5000端口。如果端口被占用，可以使用–port选项指定一个不同的端口。例如， `mlflow models serve -m runs:/<RUN_ID>/model --port 1234`

服务启动成功之后，就可以输入一些样例数据并得到预测结果。

下面的例子使用`curl`给模型服务发送一个json序列化的pandas DataFrame。对于模型服务pyfunc可接收的输入数据格式的更多信息请参考 [MLflow deployment tools documentation](https://mlflow.org/docs/latest/models.html#local-model-deployment).

```
curl -d '{"columns":["x"], "data":[[1], [-1]]}' -H 'Content-Type: application/json; format=pandas-split' -X POST localhost:5000/invocations
```

返回：

```
[1, 0]
```

更多信息, 请查看 [MLflow Models](https://mlflow.org/docs/latest/models.html).

### 记录到远程Tracking Server

在上述例子中，MLflow将相关数据记录到了其运行的服务器本地文件系统。为了中心化的管理结果或者在团队中共享，可以通过配置MLflow将数据记录到远程tracking server。接入远程tracking server：

#### 在远程服务器上启动Tracking Server

[启动tracking server](https://mlflow.org/docs/latest/tracking.html#tracking-server) 在远程服务器上。

然后可以通过设置`MLFLOW_TRACKING_URI`环境变量来 [将数据记录到tracking server](https://mlflow.org/docs/latest/tracking.html#logging-to-a-tracking-server) ，也可以在代码中设置：

```python
import mlflow
mlflow.set_tracking_uri("http://YOUR-SERVER:4040")
mlflow.set_experiment("my-experiment")
```

#### 记录到Databricks Community Edition

这部分我们不关注。